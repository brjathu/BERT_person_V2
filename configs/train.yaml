# @package _global_

defaults:
    - launcher: default.yaml
    - trainer: default.yaml

callbacks:
    model_checkpoint:
        _target_: pytorch_lightning.callbacks.ModelCheckpoint
        dirpath: ${paths.output_dir}/checkpoints
        filename: "epoch_{epoch:03d}"
        monitor: "step" #"val/mAP"
        mode: "max"
        save_last: True
        auto_insert_metric_name: False
        verbose: False # verbosity mode
        save_top_k: -1 # save k best models (determined by above metric)
        save_weights_only: False # if True, then only the modelâ€™s weights will be saved
        every_n_train_steps: null # number of training steps between checkpoints
        train_time_interval: null # checkpoints are monitored at the specified time interval
        every_n_epochs: 1 # number of epochs between checkpoints
        save_on_train_epoch_end: True # whether to run checkpointing at the end of the training epoch or the end of validation

    model_summary:
        _target_: pytorch_lightning.callbacks.RichModelSummary
        max_depth: 1

    rich_progress_bar:
        _target_: pytorch_lightning.callbacks.RichProgressBar
        refresh_rate: 1

    learning_rate_monitor:
        _target_: pytorch_lightning.callbacks.LearningRateMonitor

    # stochastic_weight_averaging:
    #     _target_: pytorch_lightning.callbacks.StochasticWeightAveraging
    #     swa_lrs: 1e-3
    #     swa_epoch_start: 1
    #     annealing_epochs: 30
    

logger:
    tensorboard:
        _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
        save_dir: "${paths.output_dir}/tensorboard/"
        version: 0
        # name: null
        # log_graph: False
        # default_hp_metric: True
        # prefix: ""

paths: 
    root_dir: ${oc.env:PROJECT_ROOT}
    data_dir: ${paths.root_dir}/data/
    log_dir: ${paths.root_dir}/logs/
    output_dir: ${hydra:runtime.output_dir}
    work_dir: ${hydra:runtime.cwd}

extras:
    print_config: True

hydra:
    run:
        dir: ${paths.log_dir}/${task_name} #/runs/${now:%Y-%m-%d}_${now:%H-%M-%S}
    sweep:
        dir: ${paths.log_dir}/${task_name} #/multiruns/${now:%Y-%m-%d}_${now:%H-%M-%S}
        subdir: ${hydra.job.num}

hydra_logging: colorlog
job_logging: colorlog



# task name, determines output directory path
task_name: "1000"
tags: ["dev"]
# slrum_job_id: ${oc.env:SLURM_ARRAY_TASK_ID}

# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: True

# simply provide checkpoint path to resume training
ckpt_path: null

# seed for random number generators in pytorch, numpy and python.random
seed: null


datamodule:
    _target_: src.datamodules.phalp_datamodule.PHALPDataModule
    cfg: ${configs}
    train: ${train}

model:
    _target_: src.models.bert_person.BERT_PERSON_LitModule
    cfg: ${configs}

configs:
    data_dir: ${paths.data_dir}
    storage_folder: "${paths.log_dir}/${task_name}/${hydra:sweep.subdir}"
    train_dataset: ava_train,kinetics_train
    test_dataset: ava_val
    train_batch_size: 8
    train_num_workers: 8
    test_batch_size: 8
    test_num_workers: 8
    test_class: ""
    test_batch_id: -1
    number_of_processes: 25
    pin_memory: True
    full_seq_render: False
    frame_length: 50
    max_people: 1
    load_other_tracks: False
    img_size: 256
    load_images: False
    use_mean_std: True
    use_mean_std_mid: False
    frame_rate_range: 1
    num_smpl_heads: 1
    finetune: False
    solver: "AdamW"
    lr: 0.001
    momentum: 0.9
    decay_steps: [10,20]
    decay_gamma: 0.1
    layer_decay: null
    ZERO_WD_1D_PARAM: True
    warmup_epochs: 5
    weight_decay: 0.05
    scheduler: "cosine"
    bottle_neck: conv
    pos_embedding: learned
    mask_ratio: 0.6
    in_feat: 485 #229
    one_euro_filter: "pred_loca,pred_pose"
    loss_type: "pose_l2,loca_l1,action_BCE"
    mask_type: "random_y"
    mask_type_test: "zero"
    test_type: "track.fullframe|" 
    encode_type: "4c"
    masked: True 
    masked_mvit: False 
    wights_path: null
    use_rakel: False
    use_relative_pose: False
    use_optimized_pose: False
    loss_on_others_action: True
    debug: False
    store_svm_vectors: False
    svm_folder: ""
    full_gt_supervision: 0
    full_pesudo_supervision: 0
    full_pesudo_supervision_c1: 0.2
    load_strict: True
    
    mixed_training: 0

    compute_map: True
    compute_acc: True

    dataset_loader : "base"

    action_space: "ava"
    
    ava:
        sampling_factor: 1
        num_action_classes: 80
        num_valid_action_classes: 60
        gt_type: "all"
        head_dropout: 0.0
        predict_valid: False
        distil_type: "both_bce"


    kinetics:
        sampling_factor: 1
        num_action_classes: 400

    loss:
        focal:
            gamma: 2
            alpha: 0.25

    extra_feat: 
        enable: ""
        pose_shape:
            dim: 229
            mid_dim: 256
            en_dim: 256
        appe:
            dim: 4096
            mid_dim: 1024
            en_dim: 256
        action:
            dim: 80
            mid_dim: 128
            en_dim: 256
        mvit:
            dim: 1152
            mid_dim: 1024
            en_dim: 1024
        hmr:
            dim: 2048
            mid_dim: 1024
            en_dim: 256
        objects:
            dim: 80
            mid_dim: 128
            en_dim: 256
        clip:
            dim: 512
            mid_dim: 128
            en_dim: 256
        vitpose:
            dim: 75
            mid_dim: 128
            en_dim: 256
        relative_pose:
            dim: 16
            mid_dim: 128
            en_dim: 256
        Dpose:
            dim: 229
            mid_dim: 256
            en_dim: 256
        img:
            dim: 512
            mid_dim: 256
            en_dim: 256
        mae:
            dim: 768
            mid_dim: 256
            en_dim: 256
        




    render:
        enable: False
        engine: "PYR"
        num_videos: 10
        vis_pred_loca: True
        vis_action_label: "person"
        res: 256
        render_up_scale: 2
        walker: "SMPL+B"  # PL, SMPL, SMPL+T, SMPL+T+B

    vit:
        depth: 6
        heads: 8
        mlp_dim: 512
        dim_head: 64
        dropout: 0.1
        emb_dropout: 0.1
        droppath: 0.1

        conv:
            pad: 1
            stride: 5

    smpl_cfg:
        SMPL:
            MODEL_PATH: data/3D
            GENDER: neutral
            MODEL_TYPE: smpl
            NUM_BODY_JOINTS: 23
            JOINT_REGRESSOR_H36M: data/3D/J_regressor_h36m.npy
            JOINT_REGRESSOR_EXTRA: data/3D/SMPL_to_J19.pkl
            TEXTURE: data/3D/texture.npz
        MODEL:
            IMAGE_SIZE: 256
            SMPL_HEAD:
                TYPE: basic
                POOL: max
                SMPL_MEAN_PARAMS: data/3D/smpl_mean_params.npz
                IN_CHANNELS: 2048
            BACKBONE:
                TYPE: resnet
                NUM_LAYERS: 50
        EXTRA:
            FOCAL_LENGTH: 5000
